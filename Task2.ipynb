{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   example_id           query  query_id  product_id product_locale esci_label  \\\n",
      "0           0   revent 80 cfm         0  B000MOO21W             us          I   \n",
      "1           1   revent 80 cfm         0  B07X3Y6B1V             us          E   \n",
      "2           2   revent 80 cfm         0  B07WDM7MQQ             us          E   \n",
      "3           3   revent 80 cfm         0  B07RH6Z8KW             us          E   \n",
      "4           4   revent 80 cfm         0  B07QJ7WYFQ             us          E   \n",
      "\n",
      "   small_version  large_version  split  \n",
      "0              0              1  train  \n",
      "1              0              1  train  \n",
      "2              0              1  train  \n",
      "3              0              1  train  \n",
      "4              0              1  train  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path of the Parquet file\n",
    "file_path = 'shopping_queries_dataset_examples.parquet'\n",
    "\n",
    "# Read the Parquet file into a pandas DataFrame\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Now you can work with the DataFrame as needed\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            query  product_id esci_label\n",
      "0                   revent 80 cfm  B000MOO21W          I\n",
      "1                   revent 80 cfm  B07X3Y6B1V          E\n",
      "2                   revent 80 cfm  B07WDM7MQQ          E\n",
      "3                   revent 80 cfm  B07RH6Z8KW          E\n",
      "4                   revent 80 cfm  B07QJ7WYFQ          E\n",
      "...                           ...         ...        ...\n",
      "2621283  �����j�[�h�p�[�x abrasus  B0063ASUY4          E\n",
      "2621284  �����j�[�h�p�[�x abrasus  B0062EZYIG          E\n",
      "2621285  �����j�[�h�p�[�x abrasus  B07H8MWBZN          S\n",
      "2621286  �����j�[�h�p�[�x abrasus  B00IZH4T9S          E\n",
      "2621287  �����j�[�h�p�[�x abrasus  B07R536DG1          E\n",
      "\n",
      "[2621288 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['example_id', 'query_id', 'product_locale', 'small_version', 'large_version', 'split'], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Clean the 'query' column\n",
    "df['query'] = df['query'].str.lower()  # Convert to lowercase\n",
    "df['query'] = df['query'].apply(lambda x: re.sub(r'\\d+', '', x))  # Remove numbers\n",
    "df['query'] = df['query'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))  # Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                query  product_id  esci_label\n",
      "0         revent  cfm  B000MOO21W           2\n",
      "1         revent  cfm  B07X3Y6B1V           1\n",
      "2         revent  cfm  B07WDM7MQQ           1\n",
      "3         revent  cfm  B07RH6Z8KW           1\n",
      "4         revent  cfm  B07QJ7WYFQ           1\n",
      "...               ...         ...         ...\n",
      "2621283  jhpx abrasus  B0063ASUY4           1\n",
      "2621284  jhpx abrasus  B0062EZYIG           1\n",
      "2621285  jhpx abrasus  B07H8MWBZN           3\n",
      "2621286  jhpx abrasus  B00IZH4T9S           1\n",
      "2621287  jhpx abrasus  B07R536DG1           1\n",
      "\n",
      "[2621288 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['esci_label'] = label_encoder.fit_transform(df['esci_label']) \n",
    "print(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original Parquet file\n",
    "df = pd.read_parquet('shopping_queries_dataset_examples.parquet')\n",
    "\n",
    "# Determine the number of rows to remove from the bottom\n",
    "rows_to_remove = 30000  # Adjust this value as needed\n",
    "\n",
    "# Remove rows from the bottom of the DataFrame\n",
    "df_trimmed = df[:-rows_to_remove]\n",
    "\n",
    "# Save the trimmed DataFrame as a new Parquet file\n",
    "df_trimmed.to_parquet('reduced_file.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id source  example_id           query  product_id product_locale  \\\n",
      "0         0  other           0   revent 80 cfm  B000MOO21W             us   \n",
      "1         0  other           1   revent 80 cfm  B07X3Y6B1V             us   \n",
      "2         0  other           2   revent 80 cfm  B07WDM7MQQ             us   \n",
      "3         0  other           3   revent 80 cfm  B07RH6Z8KW             us   \n",
      "4         0  other           4   revent 80 cfm  B07QJ7WYFQ             us   \n",
      "\n",
      "  esci_label  small_version  large_version  split  \n",
      "0          I              0              1  train  \n",
      "1          E              0              1  train  \n",
      "2          E              0              1  train  \n",
      "3          E              0              1  train  \n",
      "4          E              0              1  train  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Load the first dataset from CSV\n",
    "dataset1 = pd.read_csv('shopping_queries_dataset_sources.csv')\n",
    "\n",
    "# Load the second dataset from Parquet\n",
    "dataset2 = pq.read_table('shopping_queries_dataset_examples.parquet').to_pandas()\n",
    "\n",
    "# Perform the merge based on the 'query_id' column\n",
    "merged_dataset = pd.merge(dataset1, dataset2, on='query_id')\n",
    "\n",
    "# View the merged dataset\n",
    "print(merged_dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
